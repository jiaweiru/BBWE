seed: 1234
__set_seed: !!python/object/apply:torch.manual_seed [!ref <seed>]

original_sr: 8000
target_sr: 16000

corpus: Valentini
data_folder: /home/sturjw/Datasets/Valentini/BWE
json_folder: json
train_annotation: !ref <json_folder>/valentini_train_8_16.json
valid_annotation: !ref <json_folder>/valentini_valid_8_16.json
test_annotation: !ref <json_folder>/valentini_test_8_16.json
# corpus: VCTK
# data_folder: /home/sturjw/Datasets/VCTK
# json_folder: json
# train_annotation: !ref <json_folder>/vctk_train_8_16.json
# valid_annotation: !ref <json_folder>/vctk_valid_8_16.json
# test_annotation: !ref <json_folder>/vctk_test_8_16.json

output_folder: results/Valentini/GCCRN/8_16/adv_melgan
save_folder: !ref <output_folder>/save
samples_folder: !ref <output_folder>/test_samples

train_log: !ref <output_folder>/train_log.txt
tensorboard_logs: !ref <output_folder>/tb_logs

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>
tensorboard_train_logger: !new:speechbrain.utils.train_logger.TensorboardLogger
    save_dir: !ref <tensorboard_logs>

# FFT parameters
fft_len: 320
win_inc: 160
win_len: 320
win_fn: !name:torch.hann_window
alpha: 0.3

# Training Parameters
number_of_epochs: 400
hop_len: !ref <win_inc>
batch_size: 16
max_grad_norm: 5.0
segment_length: 8192
learning_rate: 0.0001
adam_b1: 0.5
adam_b2: 0.9
keep_checkpoint_interval: 10
res_disc: False

# Test stage:
# Visualize and save the first few audios
log_save: 10
pesq_n_jobs: 1

train_dataloader_options:
    batch_size: !ref <batch_size>
    shuffle: True
    num_workers: 8

valid_dataloader_options:
    batch_size: 1
    shuffle: False
    num_workers: 8

test_dataloader_options:
    batch_size: 1
    shuffle: False
    num_workers: 8

# Losses
generator_loss: !new:models.AEROGeneratorLoss
discriminator_loss: !new:models.SEANetDiscriminatorLoss

# Metrics
lsd: !new:models.LSD
    fft_len: 2048
    win_inc: 512
    win_len: 2048
    win_fn: !name:torch.hann_window
visqol: !new:models.ViSQOL
g_adv_loss_func: !new:models.HingeGLoss
d_adv_loss_func: !new:models.HingeDLoss
g_adv_loss: !name:models.G_adv_loss
    loss_func: !ref <g_adv_loss_func>
d_adv_loss_real: !name:models.D_loss_real
    loss_func: !ref <d_adv_loss_func>
d_adv_loss_fake: !name:models.D_loss_fake
    loss_func: !ref <d_adv_loss_func>
fm_loss: !new:models.FeatureLoss

generator: !new:models.GCCRN
    origin_sr: !ref <original_sr>
    new_sr: !ref <target_sr>
    fft_len: !ref <fft_len>
    win_inc: !ref <win_inc>
    win_len: !ref <win_len>
    alpha: !ref <alpha>
    res: True
discriminator: !new:models.MelganMultiscaleDiscriminator

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

modules:
    generator: !ref <generator>
    discriminator: !ref <discriminator>

opt_class_generator: !name:torch.optim.Adam
    lr: !ref <learning_rate>
    betas: [!ref <adam_b1>, !ref <adam_b2>]

opt_class_discriminator: !name:torch.optim.Adam
    lr: !ref <learning_rate>
    betas: [!ref <adam_b1>, !ref <adam_b2>]

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        generator: !ref <generator>
        discriminator: !ref <discriminator>
        counter: !ref <epoch_counter>